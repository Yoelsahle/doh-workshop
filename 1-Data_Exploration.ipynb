{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6d24ae",
   "metadata": {},
   "source": [
    "# Exploration of DNS-over-HTTPS Traffic Dataset\n",
    "\n",
    "The purpose of this notebook is to visualize the charactersitics of the DNS-over-HTTPS (DoH) dataset. We will calculate and visualize multiple aspects of the data to gain insights and a deeper understanding of its underlying patterns. In order to achieve this, we will use standard data exploration techniques and try to create a variety of plots, including correlations, scatter plots, and histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf8683",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "We start by loading two existing datasets of statistical features of TCP connections carrying DoH traffic into a Pandas dataframe. One dataset contains normal traffic and the other one malicious traffic. \n",
    "\n",
    "The datasets are in CSV format with a column for each feature. The Pandas dataframe allows us to read the CSV file into a Python data structure that is very similar to an Excel sheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af99664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file that contains the normal DoH traffic data. In this case, we are using the traffic generated \n",
    "# using the Cloudflare dataset.\n",
    "normal_doh_traffic_dataset = '../doh_traffic_datasets/normal_doh_traffic_cloudflare_server.csv'\n",
    "\n",
    "# The file that contains the malicious DoH traffic. We are using DoH traffic that carries a dnscat \n",
    "# tunnel for data exfiltration. \n",
    "malicious_doh_traffic_dataset = '../doh_traffic_datasets/dnscat2_data_4.csv'\n",
    "\n",
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the datasets into Pandas dataframes\n",
    "normal_traffic_df    = pd.read_csv(normal_doh_traffic_dataset)\n",
    "malicious_traffic_df = pd.read_csv(malicious_doh_traffic_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca115fe",
   "metadata": {},
   "source": [
    "### Lets see what we have in the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_traffic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "malicious_traffic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f73b8",
   "metadata": {},
   "source": [
    "### The contents of the dataset\n",
    "\n",
    "We see that the normal and malicious datasets have 16 columns. These columns are statistical features of the TCP connections related to round trip times, number of bytes, number of packets, etc. We explain what these columns mean later in this notebook.\n",
    "\n",
    "The is_doh column indicates the type of traffic. We have 1 for normal traffic and number higher than 1 for malicious traffic.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55352e12",
   "metadata": {},
   "source": [
    "## Preparing the datasets\n",
    "\n",
    "The first step is to prepare a dataset the contains both benign and malicious data. The percentage of malicious data is set to 30%. Depending on the model, we will need both malicious and bening data for training or only benign.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f226071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get a random set of malicious samples based on the contamination percentage.\n",
    "contamination              = 0.3\n",
    "seed                       = 1  \n",
    "num_malicious              = min(malicious_traffic_df.shape[0], int(normal_traffic_df.shape[0]*contamination))\n",
    "data_evaluation_malicious  = malicious_traffic_df.sample(num_malicious, random_state=seed)\n",
    "\n",
    "\n",
    "# Concatenate the normal testing data and the malicious data to\n",
    "# create the evaluation data set\n",
    "data_evaluation_df = pd.concat([normal_traffic_df, data_evaluation_malicious])\n",
    "\n",
    "\n",
    "# Shuffle the malicious samples in the whole dataset. \n",
    "data_evaluation_df = data_evaluation_df.sample(data_evaluation_df.shape[0], random_state=1)\n",
    "\n",
    "data_evaluation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14982c76",
   "metadata": {},
   "source": [
    "## Label standarization\n",
    "\n",
    "To make things easier for our models, we set the labels for normal traffic to 1 and for malicious traffic to -1. The original labels for malicious traffic are 4's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bb22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize labels. If the labels are greater than 1, it means the traffic is malicious. We set those samples to -1\n",
    "# as required by the ML Python libraries. \n",
    "normal_traffic_label = 1\n",
    "label_col            = 'is_doh'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col]>normal_traffic_label] = -1\n",
    "\n",
    "\n",
    "# Ignore warning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f75174",
   "metadata": {},
   "source": [
    "## The training and testing datasets\n",
    "We now plit the data set into training and testing datasets. The training dataset helps the model understand the difference between normal and malicious data. The testing data set is used to evaluate how well it learned this difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a57978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets. Resulting dataframes will be randomized\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We are assigning 20% of the data for testing\n",
    "split = 0.2 \n",
    "                                                                         \n",
    "# Split the data into training and testing data sets\n",
    "data_training, data_testing = train_test_split(data_evaluation_df, test_size =split, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6547cae8",
   "metadata": {},
   "source": [
    "## Save the datasets\n",
    "Finally, we save the training and testing datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warning above\n",
    "\n",
    "# Save dataset for later\n",
    "data_evaluation_df.to_csv('data_evaluation.csv', index=False)\n",
    "data_training.to_csv('data_training.csv', index=False)\n",
    "data_testing.to_csv('data_testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72782c",
   "metadata": {},
   "source": [
    "### Lets see how our datasets look now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ce644",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8c3e6f",
   "metadata": {},
   "source": [
    "### The contents of the dataset\n",
    "\n",
    "We see that the normal and malicious datasets have 16 columns labeled 0 to 15. These columns are statistical features of the TCP connections related to round trip times, number of bytes, number of packets, etc. We explain what these columns mean in notebook 0.\n",
    "\n",
    "The is_doh column indicates the type of traffic. We have 1 for normal traffic and number higher than 1 for malicious traffic.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c9f2f",
   "metadata": {},
   "source": [
    "## Correlation Matrix\n",
    "One of the initial steps in our analysis will involve creating a correlation matrix to assess the relationships between numerical variables in the dataset. This matrix will be visualized as a heatmap, making it east to identify strong correlations, which can be crucial in feature selection for machine learning models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c465be0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# We take a random sample of the trainig data set for visualization\n",
    "data_evaluation_df = data_training.sample(n = 700)\n",
    "\n",
    "# Calculate the correlations and save in new variable.\n",
    "correlation_matrix = data_evaluation_df.corr()\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Show figure\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3381a86",
   "metadata": {},
   "source": [
    "##  Can you drop the mindelay row and column from the correlation matrix? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the mindelay row and column and replot the correlation matrix\n",
    "\n",
    "# Enter the row and column name that should be dropped\n",
    "correlation_matrix = correlation_matrix.drop(index='enter_row_name_here', columns='enter_column_name_here')\n",
    "\n",
    "# recreate the figure\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Show figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e6b49d",
   "metadata": {},
   "source": [
    "## Pair Plots\n",
    "Pair plots provide an efficient way to visualize multiple pairwise relationships at once. By plotting all combinations of numerical values, we can uncover potential patterns and dependencies within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eece89",
   "metadata": {},
   "source": [
    "## Scatter Plots and Historgrams\n",
    "Scatter plots will be useful for visualizing relationships between pairs of numerical variables. By creating scatter plots, we can explore how two variables interact with eachother. This can help us identify patterns, clusters, or trends within the data.The scatter plots are in the off-diagonal of the plot matrices. Their coordinate is given by the two features that are used for the plot. \n",
    "\n",
    "Historgrams help us to understand the distribution of individual numerical variables. These histograms will allow us to assess the central tendency and spread of each variable and help in identifying potential outliers. The histograms are in the diagonal of the plot matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Define a subset of variables for the pair plot\n",
    "subset1 = ['bytes_in', 'bytes_out', 'num_pkts_in', 'num_pkts_out']\n",
    "\n",
    "# Create a pair plot with specified attributes\n",
    "sns.pairplot(data_evaluation_df, vars= subset1, diag_kind='kde', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Display the pair plot. Ignore warning\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd0b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Define a subset of variables for the pair plot\n",
    "subset2 = ['av_pkt_size_in','av_pkt_size_out', 'var_pkt_size_in', 'var_pkt_size_out']\n",
    "\n",
    "# Create a pair plot with specified attributes\n",
    "sns.pairplot(data_evaluation_df, vars= subset2, diag_kind='kde', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Display the pair plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dafb50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Define a subset of variables for the pair plot\n",
    "subset3 = ['median_in', 'median_out', 'mindelay', 'maxdelay']\n",
    "\n",
    "# Create a pair plot with specified attributes\n",
    "sns.pairplot(data_evaluation_df, vars= subset3, diag_kind='kde', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Display the pair plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Define a subset of variables for the pair plot\n",
    "subset4 = ['bytes_ration', 'num_pkts_ration', 'time', 'avgdelay']\n",
    "\n",
    "# Create a pair plot with specified attributes\n",
    "sns.pairplot(data_evaluation_df, vars= subset4, diag_kind='kde', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Display the pair plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989bb40e",
   "metadata": {},
   "source": [
    "## Examples of scatter plots of one feature vs another feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Create a scatter plot with specified attributes\n",
    "sns.scatterplot(x='bytes_in', y='bytes_out', data=data_evaluation_df, marker='o', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Set labels for the x and y axes\n",
    "plt.xlabel('bytes_in')\n",
    "plt.ylabel('bytes_out')\n",
    "\n",
    "# Set the title for the scatter plot\n",
    "plt.title('Scatter Plot of bytes_in vs bytes_out')\n",
    "\n",
    "# Display the plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3fd288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Create a scatter plot with specified attributes\n",
    "sns.scatterplot(x='num_pkts_in', y='num_pkts_out', data=data_evaluation_df, marker='o', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Set labels for the x and y axes\n",
    "plt.xlabel('num_pkts_in')\n",
    "plt.ylabel('num_pkts_out')\n",
    "\n",
    "# Set the title for the scatter plot\n",
    "plt.title('Scatter Plot of num_pkts_in vs num_pkts_out')\n",
    "\n",
    "# Display the plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e041d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Create a scatter plot with specified attributes\n",
    "sns.scatterplot(x='bytes_ration', y='num_pkts_ration', data=data_evaluation_df, marker='o', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Set labels for the x and y axes\n",
    "plt.xlabel('bytes_ration')\n",
    "plt.ylabel('num_pkts_ration')\n",
    "\n",
    "# Set the title for the scatter plot\n",
    "plt.title('Scatter Plot of bytes_ration vs num_pkts_ration')\n",
    "\n",
    "# Display the plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f17047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Create a scatter plot with specified attributes\n",
    "sns.scatterplot(x='av_pkt_size_in', y='av_pkt_size_out', data=data_evaluation_df, marker='o', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Set labels for the x and y axes\n",
    "plt.xlabel('av_pkt_size_in')\n",
    "plt.ylabel('av_pkt_size_out')\n",
    "\n",
    "# Set the title for the scatter plot\n",
    "plt.title('Scatter Plot of av_pkt_size_in vs av_pkt_size_out')\n",
    "\n",
    "# Display the plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c87b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Create a scatter plot with specified attributes\n",
    "sns.scatterplot(x='var_pkt_size_in', y='var_pkt_size_out', data=data_evaluation_df, marker='o', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Set labels for the x and y axes\n",
    "plt.xlabel('var_pkt_size_in')\n",
    "plt.ylabel('var_pkt_size_out')\n",
    "\n",
    "# Set the title for the scatter plot\n",
    "plt.title('Scatter Plot of var_pkt_size_in vs var_pkt_size_out')\n",
    "\n",
    "# Display the plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14ba03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Create a scatter plot with specified attributes\n",
    "sns.scatterplot(x='median_in', y='median_out', data=data_evaluation_df, marker='o', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Set labels for the x and y axes\n",
    "plt.xlabel('median_in')\n",
    "plt.ylabel('median_out')\n",
    "\n",
    "# Set the title for the scatter plot\n",
    "plt.title('Scatter Plot of median_in vs median_out')\n",
    "\n",
    "# Display the plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign labels \"malicious\" and \"benign\" based on values in 'label_col'\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == -1] = \"malicious\"\n",
    "data_evaluation_df[label_col][data_evaluation_df[label_col] == 1] = \"benign\"\n",
    "\n",
    "# Create a scatter plot with specified attributes\n",
    "sns.scatterplot(x='time', y='avgdelay', data=data_evaluation_df, marker='o', hue=label_col, palette= 'Set1')\n",
    "\n",
    "# Set labels for the x and y axes\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('avgdelay')\n",
    "\n",
    "# Set the title for the scatter plot\n",
    "plt.title('Scatter Plot of time vs avgdelay')\n",
    "\n",
    "# Display the plot\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205cc1a",
   "metadata": {},
   "source": [
    "By using these standard data exploration techniques and creating these diverse plots, we aim to gain a comprehensive\n",
    "understanding of the DoH traffic dataset. These visualizations will serve as a foundation for subsequent steps in our analysis, including feature engineering, model selection, and any necessary data preprocessing steps to ensure the quality and suitability of our dataset for machine learning tasks.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
